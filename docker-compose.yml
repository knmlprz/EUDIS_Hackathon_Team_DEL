services:
  llm-embedding-cpu:
    profiles: [ "cpu" ]
    build:
      context: ./llm/
    volumes:
      - ./llm/models:/models
    ports:
      - "9000:9000"

  llm-embedding-gpu:
    profiles: [ "gpu" ]
    build:
      context: ./llm/
    volumes:
      - ./llm/models:/models
    ports:
      - "9000:9000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]